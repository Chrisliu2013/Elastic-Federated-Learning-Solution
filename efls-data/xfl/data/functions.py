# Copyright 2021 Alibaba Group Holding Limited. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

from functools import cmp_to_key

import mmh3
from pyflink.common.typeinfo import Types
from pyflink.datastream import KeySelector
from pyflink.datastream.functions import RuntimeContext, KeyedProcessFunction
from pyflink.datastream.state import ValueStateDescriptor

from xfl.common.common import RunMode
from xfl.common.logger import log
from xfl.data import utils
from xfl.data.check_sum import CheckSum
from xfl.data.psi.rsa_signer import ServerRsaSigner, ClientRsaSigner
from xfl.data.store.sample_kv_store import DictSampleKvStore
from xfl.data.utils import get_sample_store_key, split_sample_store_key
from xfl.service.data_join_client import create_data_join_client
from xfl.service.data_join_server import create_data_join_server


class DefaultKeySelector(KeySelector):
  def __init__(self, bucket_num: int = 64):
    self._bucket_num = bucket_num

  def get_key(self, value):
    return mmh3.hash(value[0]) % self._bucket_num


def record_cmp(left, right):
  a = split_sample_store_key(left)
  b = split_sample_store_key(right)
  if a[1] < b[1]:
    return -1
  if a[1] > b[1]:
    return 1
  if a[0] < b[0]:
    return -1
  if a[0] > b[0]:
    return 1
  return 0


class ClientSortJoinFunc(KeyedProcessFunction):
  def __init__(
          self,
          job_name: str,
          peer_host: str,
          peer_ip: str,
          peer_port: int,
          bucket_num: int = 64,
          cmp_func=record_cmp,
          sample_store_cls=DictSampleKvStore,
          batch_size: int = 2048,
          wait_s: int = 1800,
          tls_crt: str = '',
          run_mode: RunMode = RunMode.LOCAL):
    self._job_name = job_name
    self._bucket_num = bucket_num
    self._state = None
    self._delay = 10000
    self._cmp_func = cmp_func
    self._sample_store_cls = sample_store_cls
    self._peer_host = peer_host
    self._peer_ip = peer_ip
    self._peer_port = peer_port
    self._batch_size = batch_size
    self._run_mode = run_mode
    self._wait_s = wait_s
    self._tls_crt = tls_crt
    self._subtask_index = None

  def open(self, runtime_context: RuntimeContext):
    self._state = runtime_context.get_state(ValueStateDescriptor(
      "last_modified_time", Types.LONG()))
    if self._sample_store_cls is DictSampleKvStore:
      self._sample_store = DictSampleKvStore()
    else:
      raise RuntimeError("sample_store_cls is not supported by now{}".format(self._sample_store_cls))

    self._subtask_index = runtime_context.get_index_of_this_subtask()
    if self._run_mode == RunMode.LOCAL:
      # in local model, port is generated by index of the subtask
      self._peer_port = self._peer_port + self._subtask_index
    elif self._run_mode == RunMode.K8S:
      # generate host for connecting corresponding service on server cluster
      self._peer_host = utils.get_k8s_host_name_for_bucket(self._job_name, self._subtask_index, self._peer_host)
      if self._tls_crt is None or len(self._tls_crt) == 0:
        raise RuntimeError("tls crt should not be empty in k8s mode client job!")

    self.cnt = 0

  def process_element(self, value, ctx: 'ProcessFunction.Context'):
    s = self._state.value()
    cur = ctx.timestamp() // 1000 * 1000
    if s is None or cur > s:
      self._state.update(cur)
      ctx.timer_service().register_event_time_timer(cur + self._delay)
    assert(ctx.get_current_key() == self._subtask_index)
    self._sample_store.put(get_sample_store_key(value[0], value[1]),value[2])
    self.cnt += 1

  def on_timer(self, timestamp: int, ctx: 'KeyedProcessFunction.OnTimerContext'):
    s = self._state.value()
    if timestamp >= s + self._delay:
      keys_to_join = sorted(self._sample_store.keys(), key=cmp_to_key(self._cmp_func))
      client = create_data_join_client(host=self._peer_host,
                                       ip=self._peer_ip,
                                       port=self._peer_port,
                                       job_name=self._job_name,
                                       bucket_id=self._subtask_index,
                                       run_mode=self._run_mode,
                                       tls_crt=self._tls_crt)
      check_sum = CheckSum()
      log.info(
        "Client begin to join, bucket id:{}, all size:{}, unique size:{}, subtask index{}".format(ctx.get_current_key(), self.cnt,
                                                                                 len(keys_to_join), self._subtask_index))
      client.wait_ready(timeout=self._wait_s)
      cur = 0
      while cur < len(keys_to_join):
        end = min(cur + self._batch_size, len(keys_to_join))
        request_ids = keys_to_join[cur:end]
        existence = client.sync_join(request_ids)
        res_ids = utils.gather_res(request_ids, existence=existence)
        check_sum.add_list(res_ids)
        cur = end
        for i in res_ids:
          yield str(self._subtask_index), self._sample_store.get(i)
        log.info("client sync join current idx: {}, all: {}".format(cur, len(keys_to_join)))
      log.info("End join, checkSum:{}".format(check_sum.get_check_sum()))
      res = client.finish_join(check_sum.get_check_sum())
      self._sample_store.clear()
      if not res:
        raise ValueError("Join finish error")


class ClientPsiJoinFunc(ClientSortJoinFunc):

  def __init__(self, job_name: str, peer_host: str, peer_ip: str, peer_port: int, bucket_num: int = 64,
               cmp_func=record_cmp, sample_store_cls=DictSampleKvStore, batch_size: int = 2048, wait_s: int = 1800,
               tls_crt: str = '', run_mode: RunMode = RunMode.LOCAL):
    super().__init__(job_name, peer_host, peer_ip, peer_port, bucket_num, cmp_func, sample_store_cls, batch_size,
                     wait_s, tls_crt, run_mode)

  def open(self, runtime_context: RuntimeContext):
    return super().open(runtime_context)

  def on_timer(self, timestamp: int, ctx: 'KeyedProcessFunction.OnTimerContext'):
    s = self._state.value()
    if timestamp >= s + self._delay:
      keys_to_join = sorted(self._sample_store.keys(), key=cmp_to_key(self._cmp_func))
      if self._run_mode == RunMode.K8S:
        # generate host for connecting corresponding service on server cluster
        self._peer_host = utils.get_k8s_host_name_for_bucket(self._job_name, ctx.get_current_key(), self._peer_host)
        if self._tls_crt is None or len(self._tls_crt) == 0:
          raise RuntimeError("tls crt should not be empty in k8s mode client job!")
      client = create_data_join_client(host=self._peer_host,
                                       ip=self._peer_ip,
                                       port=self._peer_port,
                                       job_name=self._job_name,
                                       bucket_id=ctx.get_current_key(),
                                       run_mode=self._run_mode,
                                       tls_crt=self._tls_crt)
      check_sum = CheckSum()
      client.wait_ready(timeout=self._wait_s)
      log.info("PSI Client Begin to fetch public key！")
      pub_key_bytes = client.request_public_key_from_server()
      self._rsa_signer = ClientRsaSigner(pub_key_bytes)
      log.info("PSI Client Begin to fetch public key OK！")
      log.info(
        "PSI Client begin to join, bucket id:{}, all size:{}, unique size:{}".format(ctx.get_current_key(),
                                                                                     self.cnt,
                                                                                 len(keys_to_join)))
      cur = 0
      while cur < len(keys_to_join):
        end = min(cur + self._batch_size, len(keys_to_join))
        request_ids = keys_to_join[cur:end]
        signed_request_ids = self._rsa_signer.sign_func(request_ids, client)
        existence = client.sync_join(signed_request_ids)
        signed_res_ids = utils.gather_res(signed_request_ids, existence=existence)
        res_ids = utils.gather_res(request_ids, existence=existence)
        check_sum.add_list(signed_res_ids)
        cur = end
        for i in res_ids:
          yield str(ctx.get_current_key()), self._sample_store.get(i)
        log.info("client sync join current idx: {}, all: {}".format(cur, len(keys_to_join)))
      log.info("End join, checkSum:{}".format(check_sum.get_check_sum()))
      res = client.finish_join(check_sum.get_check_sum())
      self._sample_store.clear()
      if not res:
        raise ValueError("Join finish error")


class ServerSortJoinFunc(KeyedProcessFunction):
  def __init__(
          self,
          job_name: str,
          port: int = 50051,
          bucket_num: int = 64,
          cmp_func=record_cmp,
          sample_store_cls=DictSampleKvStore,
          batch_size: int = 2048,
          wait_s: int = 1800,
          run_mode: RunMode = RunMode.LOCAL):
    self._job_name = job_name
    self._bucket_num = bucket_num
    self._state = None
    self._delay = 10000
    self._cmp_func = cmp_func
    self._sample_store_cls = sample_store_cls
    self._port = port
    self._wait_s = wait_s
    self._run_mode = run_mode
    self._batch_size = batch_size

  def open(self, runtime_context: RuntimeContext):
    self._state = runtime_context.get_state(ValueStateDescriptor(
      "last_modified_time", Types.LONG()))
    if self._sample_store_cls is DictSampleKvStore:
      self._sample_store = DictSampleKvStore()
    else:
      raise RuntimeError("sample_store_cls is not supported by now{}".format(self._sample_store_cls))

    self._subtask_index = runtime_context.get_index_of_this_subtask()
    if self._run_mode == RunMode.LOCAL:
      self._port = self._port + runtime_context.get_index_of_this_subtask()
    self.cnt = 0

  def process_element(self, value, ctx: 'ProcessFunction.Context'):
    s = self._state.value()
    cur = ctx.timestamp() // 1000 * 1000
    if s is None or cur > s:
      self._state.update(cur)
      ctx.timer_service().register_event_time_timer(cur + self._delay)
    assert(ctx.get_current_key() == self._subtask_index)
    self._sample_store.put(get_sample_store_key(value[0], value[1]),
                           value[2])
    self.cnt += 1

  def on_timer(self, timestamp: int, ctx: 'KeyedProcessFunction.OnTimerContext'):
    s = self._state.value()
    if timestamp >= s + self._delay:
      # create join server and wait
      data_join_server, _, k8s_resouce_handler = create_data_join_server(
        port=self._port,
        job_name=self._job_name,
        bucket_id=self._subtask_index,
        sample_kv_store=self._sample_store,
        run_mode=self._run_mode,
      )
      data_join_server.set_is_ready(True)
      # server wait for 1h
      log.info("DataJoinServer for bucket {} has been ready, "
               "unique key size: {}, all key size:{}"
               .format(self._subtask_index, self._sample_store.size(), self.cnt))
      data_join_server.wait_for_finish(timeout=self._wait_s)
      log.info("DataJoinServer for bucket {} finished! "
               "Begin to write sample".format(ctx.get_current_key()))
      for l in data_join_server.get_final_result():
        for i in l:
          yield str(ctx.get_current_key()), self._sample_store.get(i)
      self._sample_store.clear()
      if self._run_mode == RunMode.K8S:
        k8s_resouce_handler.delete()


class ServerPsiJoinFunc(ServerSortJoinFunc):
  def __init__(
          self,
          job_name: str,
          port: int = 50051,
          bucket_num: int = 64,
          cmp_func=record_cmp,
          sample_store_cls=DictSampleKvStore,
          batch_size: int = 2048,
          wait_s: int = 1800,
          run_mode: RunMode = RunMode.LOCAL):
    super().__init__(job_name, port, bucket_num, cmp_func, sample_store_cls, batch_size, wait_s, run_mode)
    self._rsa_signer = ServerRsaSigner()

  def open(self, runtime_context: RuntimeContext):
    super().open(runtime_context)
    self._rsa_signer = ServerRsaSigner()

  def process_element(self, value, ctx: 'ProcessFunction.Context'):
    s = self._state.value()
    cur = ctx.timestamp() // 1000 * 1000
    if s is None or cur > s:
      self._state.update(cur)
      ctx.timer_service().register_event_time_timer(cur + self._delay)
    key = self._rsa_signer.sign_func([get_sample_store_key(value[0], value[1])])
    self._sample_store.put(key[0],
                           value[2])
    self.cnt += 1

  def on_timer(self, timestamp: int, ctx: 'KeyedProcessFunction.OnTimerContext'):
    s = self._state.value()
    if timestamp >= s + self._delay:
      # create join server and wait
      data_join_server, _, k8s_resouce_handler = create_data_join_server(
        port=self._port,
        job_name=self._job_name,
        bucket_id=ctx.get_current_key(),
        sample_kv_store=self._sample_store,
        run_mode=self._run_mode,
        use_psi=True,
        signer=self._rsa_signer
      )
      data_join_server.set_is_ready(True)
      # server wait for 1h
      log.info("PSI DataJoinServer for bucket {} has been ready, "
               "unique key size: {}, all key size:{}"
               .format(ctx.get_current_key(), self._sample_store.size(), self.cnt))
      data_join_server.wait_for_finish(timeout=self._wait_s)
      log.info("PSI DataJoinServer for bucket {} finished! "
               "Begin to write sample".format(ctx.get_current_key()))
      for l in data_join_server.get_final_result():
        for i in l:
          yield str(ctx.get_current_key()), self._sample_store.get(i)
      self._sample_store.clear()
      if self._run_mode == RunMode.K8S:
        k8s_resouce_handler.delete()
